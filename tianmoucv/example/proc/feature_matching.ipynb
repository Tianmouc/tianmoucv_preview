{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a16979e-a451-4739-8c50-fb9e9e1229b8",
   "metadata": {},
   "source": [
    "# Haris角点和SIFT特征描述符\n",
    "\n",
    "## 这个示例展示一个在AOP上运行的，特征点检测和匹配算法，RGB上的数据用于验证\n",
    "\n",
    "调用接口：\n",
    "- tianmoucv.proc.features.(HarrisCorner,sift,hog)\n",
    "- tianmoucv.proc.tracking.(feature_matching,mini_l2_cost_matching,align_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf67deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee50ac2-3b66-41a3-b044-c9e4cfadf388",
   "metadata": {},
   "source": [
    "## 必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3840fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys,os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tianmoucv.isp import lyncam_raw_comp,demosaicing_npy,SD2XY\n",
    "from tianmoucv.proc.features import HarrisCorner,sift,hog\n",
    "from tianmoucv.proc.tracking import feature_matching,mini_l2_cost_matching,align_images\n",
    "import cv2\n",
    "from tianmoucv.data import TianmoucDataReader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a327b-fb89-4d52-b5d6-a199181d0d91",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a960b-c7d3-4c3a-a067-28f952c00f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train='/data/lyh/tianmoucData/tianmoucReconDataset/train/'\n",
    "dirlist = os.listdir(train)\n",
    "traindata = [train + e for e in dirlist]\n",
    "\n",
    "val='/data/lyh/tianmoucData/tianmoucReconDataset/test/'\n",
    "vallist = os.listdir(val)\n",
    "valdata = [val + e for e in vallist]\n",
    "key_list = []\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in traindata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in valdata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "        \n",
    "all_data = valdata + traindata\n",
    "key_list = ['underbridge_hdr_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c8768-73a2-4901-8b47-ee905d13bed6",
   "metadata": {},
   "source": [
    "# 特征点检测和匹配，利用相隔150帧的SD做匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import time\n",
    "from tianmoucv.proc.reconstruct import laplacian_blending\n",
    "from IPython.display import clear_output\n",
    "\n",
    "key= 'outdoor_bridge_3'\n",
    "dataset = TianmoucDataReader(all_data,MAXLEN=500*1,matchkey=key,speedUpRate=1)\n",
    "\n",
    "imlist = []\n",
    "for sampleid in range(len(dataset)):\n",
    "    if sampleid<95:\n",
    "        continue\n",
    "    if sampleid>99:\n",
    "        break\n",
    "    else:\n",
    "        ###############################\n",
    "        clear_output()\n",
    "        sample = dataset[sampleid]\n",
    "        F1 = sample['F0']\n",
    "        tsdiff = sample['rawDiff']/255.0\n",
    "        threshed_tsdiff = tsdiff[:,0,...].permute(1,2,0)\n",
    "        SD = threshed_tsdiff[...,1:]\n",
    "        TD = threshed_tsdiff[...,0]\n",
    "        Ix1,Iy1= SD2XY(SD)\n",
    "        gray = laplacian_blending(-Ix1,-Iy1,iteration=20)\n",
    "        gray_laplac1 = F.interpolate(torch.Tensor(gray).unsqueeze(0).unsqueeze(0), size=(320,640), mode='bilinear').squeeze(0).squeeze(0)\n",
    "\n",
    "        # 选择5帧后的数据做匹配验证\n",
    "        sample = dataset[sampleid+5]\n",
    "        F2 = sample['F0']\n",
    "        tsdiff = sample['rawDiff']/255.0\n",
    "        threshed_tsdiff = tsdiff[:,0,...].permute(1,2,0)\n",
    "        SD = threshed_tsdiff[...,1:]\n",
    "        TD = threshed_tsdiff[...,0]\n",
    "        Ix2,Iy2= SD2XY(SD)\n",
    "        gray = laplacian_blending(-Ix2,-Iy2,iteration=20)\n",
    "        gray_laplac2 = F.interpolate(torch.Tensor(gray).unsqueeze(0).unsqueeze(0), size=(320,640), mode='bilinear').squeeze(0).squeeze(0)\n",
    "\n",
    "        gray_laplac1 = (gray_laplac1 - torch.min(gray_laplac1)) / (torch.max(gray_laplac1) - torch.min(gray_laplac1) + 1e-3) \n",
    "        gray_laplac2 = (gray_laplac2 - torch.min(gray_laplac2)) / (torch.max(gray_laplac2) - torch.min(gray_laplac2) + 1e-3) \n",
    "        \n",
    "        F1_g = torch.stack([gray_laplac1]*3,dim=-1)\n",
    "        F2_g = torch.stack([gray_laplac2]*3,dim=-1)\n",
    "\n",
    "        ## 计算harris角点\n",
    "        featureList1 = []\n",
    "        kp1=[]\n",
    "        featureList2 = []\n",
    "        kp2=[]\n",
    "        k = 0.01\n",
    "        th = 0.01\n",
    "        nmsSize= 15\n",
    "        startT = time.time()\n",
    "        idmap,R = HarrisCorner(Ix1,Iy1,k=k,th=th,nmsSize=nmsSize)\n",
    "        endT = time.time()\n",
    "        idmap2,R = HarrisCorner(Ix2,Iy2,k=k,th=th,nmsSize=nmsSize)\n",
    "        print('corner detect cost:',endT-startT,'s')\n",
    "\n",
    "        canvas_rgb = np.zeros([320,1280,3])\n",
    "        canvas_rgb[:,:640,:] = F1\n",
    "        canvas_rgb[:,640:,:] = F2\n",
    "        \n",
    "        canvas = np.zeros([320,1280,3])\n",
    "        canvas[:,:640,:] = F1_g.numpy()\n",
    "        canvas[:,640:,:] = F2_g.numpy()\n",
    "        \n",
    "        #(step1)第一张图的feature list\n",
    "        for i in range(idmap.shape[0]):\n",
    "            for j in range(idmap.shape[1]):\n",
    "                if idmap[i,j]>0:\n",
    "                    cv2.circle(canvas,(j*2,i*2),4,(0,0,255))\n",
    "                    kp1.append([i,j])\n",
    "        #(step2)第二张图的feature list\n",
    "        for i in range(idmap2.shape[0]):\n",
    "            for j in range(idmap2.shape[1]):\n",
    "                if idmap2[i,j]>0:\n",
    "                    cv2.circle(canvas,(j*2+640,i*2),4,(255,0,0))\n",
    "                    kp2.append([i,j])\n",
    "\n",
    "        #(step3)计算两张图对应fp list的特征描述子\n",
    "        startT = time.time()\n",
    "        kp1,featureList1 = sift(Ix1,Iy1,kp1)\n",
    "        endT = time.time()\n",
    "        print('feature extract cost:',endT-startT,'s')\n",
    "        kp2,featureList2 = sift(Ix2,Iy2,kp2) \n",
    "        print('good kp1/2:',len(kp1),len(kp2))\n",
    "        #print('>>>>>KP1:',kp1)\n",
    "        #print('>>>>>KP2:',kp2)\n",
    "        #mapping to rgb coordinate\n",
    "        kp1 = [ (p[0]*2,p[1]*2) for p in kp1 ]\n",
    "        kp2 = [ (p[0]*2,p[1]*2) for p in kp2 ]\n",
    "        fl1 = torch.stack(featureList1,dim=0).view(len(kp1),-1)\n",
    "        fl2 = torch.stack(featureList2,dim=0).view(len(kp2),-1)\n",
    "\n",
    "        #(step4)匹配特征\n",
    "        startT = time.time()\n",
    "        matches = feature_matching(fl1, fl2, ratio=0.75)\n",
    "        endT = time.time()\n",
    "        print('matched kp:',len(matches),'cost time:',endT-startT,'s')\n",
    "        canvas_wp, H = align_images(F1.copy(),kp1, kp2, matches, canvas) \n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(9,3))\n",
    "        plt.imshow(canvas)\n",
    "        plt.show()\n",
    "        imlist.append(canvas)\n",
    "        \n",
    "        plt.figure(figsize=(9,3))\n",
    "        plt.imshow(canvas_rgb)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(9,3))\n",
    "        plt.subplot(1,2,1)  \n",
    "        plt.imshow(canvas_wp)\n",
    "        plt.subplot(1,2,2)  \n",
    "        plt.imshow((F2+canvas_wp)/2)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video(frame_list,name,Val_size=(512,256),Flip=False):\n",
    "    fps = 30     \n",
    "    size = (Val_size[0], Val_size[1]*2) # 需要转为视频的图片的尺寸\n",
    "    out = cv2.VideoWriter(name,0x7634706d , fps, size)\n",
    "    for frame in frame_list:\n",
    "        frame = (frame-np.min(frame))/(np.max(frame)-np.min(frame)) * 255\n",
    "        frame2 = frame.astype(np.uint8)\n",
    "        out.write(frame2)\n",
    "    out.release()\n",
    "    \n",
    "images_to_video(imlist,'./'+key+'.mp4',Val_size=(640,320),Flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cdabe-5dd3-4dbb-96ba-20d08308db12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
