{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515c312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tianmoucv.data import TianmoucDataReader\n",
    "\n",
    "train='/data/lyh/tianmoucData/tianmoucReconDataset/train/'\n",
    "dirlist = os.listdir(train)\n",
    "traindata = [train + e for e in dirlist]\n",
    "\n",
    "val='/data/lyh/tianmoucData/tianmoucReconDataset/test/'\n",
    "vallist = os.listdir(val)\n",
    "valdata = [val + e for e in vallist]\n",
    "key_list = []\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in traindata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e)\n",
    "        key_list.append(e)\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in valdata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e)\n",
    "        key_list.append(e)\n",
    "        \n",
    "all_data = valdata + traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f0d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from tianmoucv.proc.opticalflow.spy_net import DenseOF_NN\n",
    "\n",
    "local_rank = 0\n",
    "device = torch.device('cuda:'+str(local_rank))\n",
    "OFNet = DenseOF_NN((320,640))\n",
    "OFNet.to(device)\n",
    "OFNet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04561ba1",
   "metadata": {},
   "source": [
    "# 光流计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5be39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "sys.path.append(\"../demo\")\n",
    "from tianmoucv.isp import *\n",
    "from tianmoucv.proc.opticalflow import interpolate_image,flow_to_image\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "imlist = []\n",
    "noiseThresh = 0\n",
    "W = 640\n",
    "H = 320\n",
    "acctime= 1\n",
    "gridX, gridY = np.meshgrid(np.arange(W), np.arange(H))\n",
    "\n",
    "dataset = TianmoucDataReader(all_data,MAXLEN=400,matchkey = 'test_exam_fan4')\n",
    "\n",
    "show_list = []\n",
    "for index in range(len(dataset)):\n",
    "    if index <=0:\n",
    "        continue\n",
    "    elif index > 10:\n",
    "        break\n",
    "    else:\n",
    "        print('rpogress:',index,'/',len(dataset))\n",
    "        sample = dataset[index]\n",
    "        F0 = sample['F0']\n",
    "        F1 = sample['F1']\n",
    "        tsdiff = sample['tsdiff']\n",
    "        F0show = F0.copy()\n",
    "        show_img = F0show.copy()\n",
    "        for b in range(25//acctime):\n",
    "            SD0 = 0\n",
    "            SD1 = 0\n",
    "            Tdiff = 0\n",
    "                        \n",
    "            with torch.no_grad():\n",
    "                #print(tsdiff.shape)\n",
    "                rawflow = OFNet.forward_time_range(tsdiff.unsqueeze(0), t1=b*acctime, t2=(b+1)*acctime) #输出值0~1\n",
    "                rawflow = rawflow.cpu()\n",
    "                \n",
    "            SD0 = tsdiff[1:,b*acctime,...].unsqueeze(0).to(device)\n",
    "            SD1 = tsdiff[1:,(b+1)*acctime,...].unsqueeze(0).to(device)\n",
    "            Tdiff= tsdiff[0:1,b*acctime:(b+1)*acctime,...].to(device)\n",
    "            Tdiff = torch.sum(Tdiff,dim=1).unsqueeze(0)\n",
    "            \n",
    "            td = -tsdiff[0,(b+1)*acctime,...].to(device)\n",
    "            tdiff_show = np.stack([td.cpu()*255]*3,axis=2).astype(np.uint8)\n",
    "            tdiff_show[abs(tdiff_show)<8]=0\n",
    "            \n",
    "            Tdiff = F.interpolate(Tdiff,(320,640),mode='bilinear')\n",
    "            SD0 = F.interpolate(SD0,(320,640),mode='bilinear')\n",
    "            SD1 = F.interpolate(SD1,(320,640),mode='bilinear')\n",
    "\n",
    "            \n",
    "            u = rawflow[0,0:1,:, :]\n",
    "            v = rawflow[0,1:2,:, :]\n",
    "            flow_show = flow_to_image(rawflow[0,...].permute(1,2,0).numpy())\n",
    "            flow_show = torch.Tensor(cv2.resize(flow_show,(640,320)))/255.0\n",
    "            flow_show = (flow_show*255).numpy().astype(np.uint8)\n",
    "            \n",
    "            mask = np.mean(flow_show,axis=-1) > 225\n",
    "            flow_show[np.stack([mask]*3,axis=-1)]=0\n",
    "            \n",
    "            show_img = interpolate_image(show_img,u,v)\n",
    "            sparsity = 8\n",
    "            scale = 10\n",
    "            for w in range(640//sparsity):\n",
    "                for h in range(320//sparsity):\n",
    "                    x = int(w*sparsity)\n",
    "                    y = int(h*sparsity)\n",
    "                    u_ij = -u[0,y,x]\n",
    "                    v_ij = -v[0,y,x]\n",
    "                    color = flow_show[y,x,:]\n",
    "                    color = tuple([int(e+20) for e in color])\n",
    "                    if (u_ij**2+v_ij**2)>5:\n",
    "                        cv2.arrowedLine(flow_show, (x,y), (int(x+u_ij*scale),int(y+v_ij*scale)), color,2, tipLength=0.15)\n",
    "            \n",
    "            tdiff_show_tensor = torch.Tensor(tdiff_show.copy())\n",
    "            flow_show_tensor = torch.Tensor(flow_show)\n",
    "            mask = torch.stack([torch.mean(flow_show_tensor,dim=-1)>0]*3,dim=-1)\n",
    "            tdiff_show_tensor[mask] = flow_show_tensor[mask]/255.0\n",
    "            tdiff_show_merge = tdiff_show_tensor.numpy()\n",
    "            imshow = np.concatenate([flow_show/255.0,tdiff_show,tdiff_show_merge],axis=0)\n",
    "            show_list.append(imshow)\n",
    "            \n",
    "            if b%10==0:\n",
    "                plt.figure(figsize=(18,10))\n",
    "                plt.axis('off') \n",
    "                plt.subplot(2,3,1)\n",
    "                plt.imshow(SD0[0,0,...].cpu(),cmap='gray')\n",
    "                plt.subplot(2,3,2)\n",
    "                plt.imshow(Tdiff[0,0,...].cpu(),cmap='gray')\n",
    "                plt.axis('off') \n",
    "                plt.subplot(2,3,4)\n",
    "                plt.imshow(F0show)\n",
    "                plt.subplot(2,3,5)\n",
    "                plt.imshow(flow_show/255.0)\n",
    "                plt.subplot(2,3,6)\n",
    "                plt.imshow(imshow)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7864e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def images_to_video(frame_list,name,Val_size=(512,256),Flip=False):\n",
    "    fps = 30         \n",
    "    size = (Val_size[0], Val_size[1]) # 需要转为视频的图片的尺寸\n",
    "    out = cv2.VideoWriter(name,0x7634706d , fps, size)\n",
    "    count = 0\n",
    "    for frame in frame_list:\n",
    "        count += 1\n",
    "        frame *= 255\n",
    "        frame = frame.astype(np.uint8)\n",
    "        if count % 20 ==0:\n",
    "            plt.figure(figsize=(16,8))\n",
    "            plt.imshow(frame[:,:,[2,1,0]])\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "    \n",
    "images_to_video(show_list,'./tianmouc_of_multiple_scale_nn.mp4',Val_size=(640,320*3),Flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df9c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
