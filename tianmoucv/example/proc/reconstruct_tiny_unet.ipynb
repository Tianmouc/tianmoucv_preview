{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f975fb21-58c2-4682-9565-6965173cc6a6",
   "metadata": {},
   "source": [
    "# 轻量化视频重建\n",
    "\n",
    "## 这个示例展示如何使用一个端到端网络融合两个数据通路重建原始场景\n",
    "\n",
    "调用接口：\n",
    "- from tianmoucv.proc.reconstruct.TianmoucRecon_tiny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7018a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205a09e",
   "metadata": {},
   "source": [
    "## 引入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbb65d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys,os, math,time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tianmoucv.data import TianmoucDataReader\n",
    "import torch.nn.functional as F\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051ac49-5ab7-46d3-8987-7348c47ec4eb",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31469ba0-d292-4d09-81a1-cbd7889fceea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train='/data/lyh/tianmoucData/tianmoucReconDataset/train/'\n",
    "dirlist = os.listdir(train)\n",
    "traindata = [train + e for e in dirlist]\n",
    "\n",
    "val='/data/lyh/tianmoucData/tianmoucReconDataset/test/'\n",
    "vallist = os.listdir(val)\n",
    "valdata = [val + e for e in vallist]\n",
    "key_list = []\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in traindata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in valdata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "        \n",
    "all_data = valdata + traindata\n",
    "key_list = ['underbridge_hdr_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe5b60-2de4-4067-9bc6-edfc175bfa7c",
   "metadata": {},
   "source": [
    "## TinyUNet重建网络调用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519407bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from tianmoucv.proc.reconstruct import TianmoucRecon_tiny\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "reconstructor = TianmoucRecon_tiny(ckpt_path=None,_optim=False).to(device)#某些版本python和pytorch无法使用_optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8d860",
   "metadata": {},
   "source": [
    "# 融合图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "from tianmoucv.isp import vizDiff\n",
    "\n",
    "def images_to_video(frame_list,name,size=(640,320),Flip=True):\n",
    "    fps = 30        \n",
    "    ftmax = 1\n",
    "    ftmin = 0\n",
    "    out = cv2.VideoWriter(name,0x7634706d , fps, size)\n",
    "    for ft in frame_list:\n",
    "        ft = (ft-ftmin)/(ftmax-ftmin)\n",
    "        ft[ft>1]=1\n",
    "        ft[ft<0]=0\n",
    "        ft2 = (ft*255).astype(np.uint8)\n",
    "        out.write(ft2)\n",
    "    out.release()\n",
    "\n",
    "\n",
    "key_list = ['flicker_4']\n",
    "for key in key_list:\n",
    "    dataset = TianmoucDataReader(all_data,MAXLEN=500,matchkey=key,speedUpRate=1)\n",
    "    dataLoader = torch.utils.data.DataLoader(dataset, batch_size=1,\\\n",
    "                                          num_workers=4, pin_memory=False, drop_last = False)\n",
    "    img_list = []\n",
    "    count = 0\n",
    "    for index,sample in enumerate(dataLoader,0):\n",
    "        if index<0:\n",
    "            continue\n",
    "        if index<= 30:\n",
    "            F0 = sample['F0'][0,...]\n",
    "            F1 = sample['F1'][0,...]\n",
    "            tsdiff = sample['tsdiff'][0,...]\n",
    "            #正向重建\n",
    "            reconstructed_b1 = reconstructor(F0.to(device),tsdiff.to(device), t=-1).float()\n",
    "            inverse_tsdiff = torch.zeros_like(tsdiff)\n",
    "            timelen = tsdiff.shape[1]\n",
    "            for t in range(timelen):\n",
    "                if t < timelen-1:\n",
    "                    inverse_tsdiff[0,t,...] = tsdiff[0,timelen-t-1,...] * -1\n",
    "                inverse_tsdiff[1,t,...] = tsdiff[1,timelen-t-1,...]\n",
    "                inverse_tsdiff[2,t,...] = tsdiff[2,timelen-t-1,...]\n",
    "            \n",
    "            #逆向重建\n",
    "            reconstructed_b2 = reconstructor(F1.to(device),inverse_tsdiff.to(device), t=-1).float()\n",
    "            #求平均压制TD噪声\n",
    "            reconstructed_b = torch.zeros_like(reconstructed_b1)\n",
    "            \n",
    "            for t in range(timelen):\n",
    "                reconstructed_b[t,...] = (reconstructed_b1[t,...]+reconstructed_b2[timelen-t-1])/2\n",
    "\n",
    "            #最后一帧可以扔掉，或者跟下一次的重建的第0帧做个平均，降低一些闪烁感\n",
    "            for t in range(timelen-1):\n",
    "\n",
    "                tsd_rgb = tsdiff[:,t,...].cpu().permute(1,2,0)*255\n",
    "                td = tsd_rgb.cpu()[:,:,0]\n",
    "                sd = tsd_rgb.cpu()[:,:,1:]\n",
    "                rgb_sd = vizDiff(sd,thresh=3)\n",
    "                rgb_td = vizDiff(td,thresh=3)\n",
    "\n",
    "                #数据可视化\n",
    "                rgb_cat = torch.cat([rgb_sd,rgb_td],dim=1)\n",
    "                rgb_tsd = F.interpolate(rgb_cat.unsqueeze(0), scale_factor=0.5, mode='bilinear', align_corners=True).squeeze(0).permute(1,2,0)\n",
    "\n",
    "                reconstructed = reconstructed_b[t,...].cpu()\n",
    "                showim = torch.cat([F0,rgb_tsd,reconstructed.permute(1,2,0)],dim=1).numpy()\n",
    "                        \n",
    "                w = 640\n",
    "                h = 320\n",
    "                # 标注文字\n",
    "                cv2.putText(showim,\"e-GT:\"+str(t),(int(w*1.5)+12,36),cv2.FONT_HERSHEY_SIMPLEX,0.75,(0,0,0),2)\n",
    "                cv2.putText(showim,\"SD:\"+str(t),(int(w)+12,24),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,0),2)\n",
    "                cv2.putText(showim,\"TD:\"+str(t),(int(w)+12,160+24),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,0),2)\n",
    "                cv2.putText(showim,\"COP:0\",(12,36),cv2.FONT_HERSHEY_SIMPLEX,0.75,(0,0,0),2)\n",
    "        \n",
    "                if t==12:\n",
    "                    clear_output(wait=True)\n",
    "                    plt.figure(figsize=(8,3))\n",
    "                    plt.subplot(1,1,1)  \n",
    "                    plt.imshow(showim)\n",
    "                    plt.show()\n",
    "                img_list.append(showim[...,[2,1,0]])\n",
    "        else:\n",
    "            break\n",
    "    images_to_video(img_list,'./viz_'+key+'.mp4',size=(640*2+320,320),Flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc393f-cb9e-4281-b514-d7b4d3c3cd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
