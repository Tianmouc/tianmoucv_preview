{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59340793-443d-4ffc-9d9f-0a7a981456ca",
   "metadata": {},
   "source": [
    "# 基于SpyNet的光流网络\n",
    "\n",
    "## 这个示例展示一个在AOP上运行的，推理快速的端到端光流网络\n",
    "\n",
    "调用接口：\n",
    "- tianmoucv.proc.opticalflow.TianmoucOF_SpyNet\n",
    "- 输入方式1: 输入sample中的tsdiff，指定计算t1~t2\n",
    "- 输入方式2: 输入ti对应的sd1和t2对应的sd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96039e8-1e2d-4a10-a083-576be348b286",
   "metadata": {},
   "source": [
    "## 必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d8d01-0089-4fc3-8091-dcfa41f40c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys,os, math,time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tianmoucv.data import TianmoucDataReader\n",
    "import torch.nn.functional as F\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c816881-7937-4506-a2a7-fda7c2bc7442",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907aacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train='/data/lyh/tianmoucData/tianmoucReconDataset/train/'\n",
    "dirlist = os.listdir(train)\n",
    "traindata = [train + e for e in dirlist]\n",
    "\n",
    "val='/data/lyh/tianmoucData/tianmoucReconDataset/test/'\n",
    "vallist = os.listdir(val)\n",
    "valdata = [val + e for e in vallist]\n",
    "key_list = []\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in traindata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in valdata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "        \n",
    "all_data = valdata + traindata\n",
    "key_list = ['underbridge_hdr_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21165486-2d6b-4894-ae02-976a64eb1a3f",
   "metadata": {},
   "source": [
    "## 光流网络初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b0d5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from tianmoucv.proc.opticalflow import TianmoucOF_SpyNet\n",
    "\n",
    "local_rank = 7\n",
    "device = torch.device('cuda:'+str(local_rank))\n",
    "OFNet = TianmoucOF_SpyNet((320,640),_optim=False)\n",
    "OFNet.to(device)\n",
    "OFNet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0913ce",
   "metadata": {},
   "source": [
    "# 光流计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305e19d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "from tianmoucv.isp import *\n",
    "from tianmoucv.proc.opticalflow import interpolate_image,flow_to_image\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "imlist = []\n",
    "noiseThresh = 0\n",
    "W = 640\n",
    "H = 320\n",
    "acctime= 5\n",
    "gridX, gridY = np.meshgrid(np.arange(W), np.arange(H))\n",
    "\n",
    "\n",
    "def images_to_video(frame_list,name,size=(640,320),Flip=True):\n",
    "    fps = 25        \n",
    "    ftmax = 1\n",
    "    ftmin = 0\n",
    "    out = cv2.VideoWriter(name,0x7634706d , fps, size)\n",
    "    for ft in frame_list:\n",
    "        ft = (ft-ftmin)/(ftmax-ftmin)\n",
    "        ft[ft>1]=1\n",
    "        ft[ft<0]=0\n",
    "        ft2 = (ft*255).astype(np.uint8)\n",
    "        out.write(ft2)\n",
    "    out.release()\n",
    "\n",
    "show_list = []\n",
    "\n",
    "\n",
    "for key in key_list:\n",
    "    dataset = TianmoucDataReader(all_data,MAXLEN=400,matchkey = key,print_info=False)\n",
    "    for index in range(len(dataset)):\n",
    "        if index<= 5:\n",
    "            sample = dataset[index]\n",
    "            F0 = sample['F0'].numpy()\n",
    "            F1 = sample['F1'].numpy()\n",
    "            tsdiff = sample['tsdiff']\n",
    "            F0show = F0.copy()\n",
    "            show_img = F0show.copy()\n",
    "\n",
    "            # you may choose the accumulation time(minimum is 1, uint is frame index)\n",
    "            for b in range((tsdiff.shape[1]-1)//acctime):\n",
    "\n",
    "                # conduct optical flow estimation using rafe\n",
    "                with torch.no_grad():\n",
    "                    # 输入方式1，如果t1,t2都在 sample的 time range 内部\n",
    "                    #rawflow = OFNet.forward_time_range(tsdiff.unsqueeze(0), t1=b*acctime, t2=(b+1)*acctime) #输出值0~1\n",
    "                    \n",
    "                    # 输入方式2， 通用：\n",
    "                    td = torch.sum(tsdiff[0:1,(b)*acctime:(b+1)*acctime,...],dim=1)\n",
    "                    sd0 = tsdiff[1:,(b)*acctime,...]\n",
    "                    sd1 = tsdiff[1:,(b+1)*acctime,...]\n",
    "                    rawflow = OFNet(td,sd0,sd1,print_fps = True) #输出值0~1\n",
    "                    rawflow = rawflow.cpu()\n",
    "                    \n",
    "                #visualization\n",
    "                td = tsdiff[0,(b+1)*acctime,...] * 128\n",
    "                rgb_td = vizDiff(td.cpu(),thresh=3,bg_color='black')\n",
    "                tdiff_show = rgb_td.numpy() \n",
    "\n",
    "                #optical flow visualization\n",
    "                u = rawflow[0,0:1,:, :] #x\n",
    "                v = rawflow[0,1:2,:, :] #y\n",
    "                flow_show = flow_to_image(rawflow[0,...].permute(1,2,0).numpy())\n",
    "                flow_show = torch.Tensor(cv2.resize(flow_show,(640,320)))\n",
    "                \n",
    "                mask = torch.mean(flow_show,dim=-1) > 225\n",
    "                flow_show[torch.stack([mask]*3,dim=-1)]=0\n",
    "                flow_show = flow_show.numpy()\n",
    "                \n",
    "                show_img = interpolate_image(show_img,u,v)\n",
    "\n",
    "                # add arrows to optical flow\n",
    "                sparsity = 4\n",
    "                scale = 5\n",
    "                for w in range(640//sparsity):\n",
    "                    for h in range(320//sparsity):\n",
    "                        x = int(w*sparsity)\n",
    "                        y = int(h*sparsity)\n",
    "                        u_ij = -u[0,y,x]\n",
    "                        v_ij = -v[0,y,x]\n",
    "                        color = flow_show[y,x,:]\n",
    "                        color = tuple([int(e+20) for e in color])\n",
    "                        if (u_ij**2+v_ij**2)>5:\n",
    "                            cv2.arrowedLine(flow_show, (x,y), (int(x+u_ij*scale),int(y+v_ij*scale)), color,2, tipLength=0.15)\n",
    "\n",
    "                #concate for output\n",
    "                tdiff_show_tensor = torch.Tensor(tdiff_show.copy())\n",
    "                flow_show_tensor = torch.Tensor(flow_show)\n",
    "                mask = torch.stack([torch.mean(flow_show_tensor,dim=-1)>0]*3,dim=-1)\n",
    "                tdiff_show_tensor[mask] = flow_show_tensor[mask]/255.0\n",
    "                tdiff_show_merge = tdiff_show_tensor.numpy()\n",
    "                imshow = np.concatenate([flow_show/255.0,tdiff_show,tdiff_show_merge],axis=0)\n",
    "                imshow1 = np.concatenate([flow_show/255.0,F0show],axis=1)\n",
    "                imshow2 = np.concatenate([tdiff_show,tdiff_show_merge],axis=1)\n",
    "                imshow = np.concatenate([imshow1,imshow2],axis=0)\n",
    "                show_list.append(imshow)\n",
    "    \n",
    "                if b %10 ==0:\n",
    "                    clear_output()\n",
    "                    plt.figure(figsize=(6,3))\n",
    "                    plt.axis('off') \n",
    "                    plt.imshow(imshow)\n",
    "                    plt.show()\n",
    "        else:\n",
    "            clear_output()\n",
    "            output_dir = './output'\n",
    "            if not os.path.exists(output_dir):\n",
    "                 os.mkdir(output_dir)\n",
    "            output_name = os.path.join(output_dir,'OF_RAFT_viz_'+key+'.mp4')\n",
    "            images_to_video(show_list,output_name,size=(640*2,320*2),Flip=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d581593-d1f4-4d19-9fbc-3bbc4faba689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
