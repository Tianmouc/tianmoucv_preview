{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea7f03-9d31-44ec-b283-a93bb181f6b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251d5eb-c5c6-456c-b0ad-cb04923a74f2",
   "metadata": {},
   "source": [
    "# 基于HS方法的实时光流计算\n",
    "\n",
    "## 这个示例展示一个在AOP上运行的LK方法\n",
    "\n",
    "调用接口：\n",
    "- tianmoucv.proc.opticalflow.HS_optical_flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e316a-c035-4c79-8ac3-1cfea8ae4a8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train='/data/lyh/tianmoucData/tianmoucReconDataset/train/'\n",
    "dirlist = os.listdir(train)\n",
    "traindata = [train + e for e in dirlist]\n",
    "\n",
    "val='/data/lyh/tianmoucData/tianmoucReconDataset/test/'\n",
    "vallist = os.listdir(val)\n",
    "valdata = [val + e for e in vallist]\n",
    "key_list = []\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in traindata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in valdata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "        \n",
    "all_data = valdata + traindata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15557c58-034b-42a4-8766-8debe520c392",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 光流计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499c488-516a-4f05-9a28-67a948343b24",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import cv2, math\n",
    "import torch.nn as nn\n",
    "\n",
    "from tianmoucv.proc.reconstruct import TD_integration,SD_integration\n",
    "from tianmoucv.isp import lyncam_raw_comp,demosaicing_npy,vizDiff\n",
    "from tianmoucv.data import TianmoucDataReader\n",
    "from tianmoucv.isp import SD2XY\n",
    "from tianmoucv.proc.reconstruct import laplacian_blending\n",
    "from tianmoucv.proc.opticalflow import interpolate_image,flow_to_image\n",
    "from tianmoucv.proc.opticalflow import HS_optical_flow\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "speedUpRate = 1\n",
    "count = 0\n",
    "    \n",
    "def images_to_video(frame_list,name,size=(640,320),Flip=True):\n",
    "    fps = 25        \n",
    "    ftmax = 1\n",
    "    ftmin = 0\n",
    "    out = cv2.VideoWriter(name,0x7634706d , fps, size)\n",
    "    for ft in frame_list:\n",
    "        ft = (ft-ftmin)/(ftmax-ftmin)\n",
    "        ft[ft>1]=1\n",
    "        ft[ft<0]=0\n",
    "        ft2 = (ft*255).astype(np.uint8)\n",
    "        out.write(ft2)\n",
    "    out.release()\n",
    "\n",
    "\n",
    "img_list = []\n",
    "accumTime = 1\n",
    "noiseThresh  = 6\n",
    "lambda_of_HS = 8\n",
    "\n",
    "for key in key_list:\n",
    "    dataset = TianmoucDataReader(all_data,matchkey = 'test_exam_full3',MAXLEN=500)\n",
    "    PSNR = 0\n",
    "    img_list = []\n",
    "    for index in range(len(dataset)):\n",
    "        if index<= 5:\n",
    "            print('rpogress:',index,'/',len(dataset))\n",
    "            \n",
    "            sample = dataset[index]\n",
    "            F0 = sample['F0'].numpy()\n",
    "            F1 = sample['F1'].numpy()\n",
    "            tsdiff = sample['rawDiff']\n",
    "            F0show = F0.copy()\n",
    "            show_img = F0show.copy()\n",
    "            print('Time len:',tsdiff.shape[1])\n",
    "            \n",
    "            for b in range((tsdiff.shape[1]-1)//accumTime):\n",
    "                sd = 0\n",
    "                td = 0\n",
    "                TD = 0\n",
    "                #积累几帧diff\n",
    "                for t in range(accumTime):\n",
    "                    threshed_tsdiff = tsdiff[:,b*accumTime+t,...].permute(1,2,0)\n",
    "                    threshed_tsdiff[abs(threshed_tsdiff)<noiseThresh] = 0\n",
    "                    SD = threshed_tsdiff[...,1:]\n",
    "                    TD = threshed_tsdiff[...,0]\n",
    "                    Ix,Iy= SD2XY(SD)\n",
    "                    sd += torch.FloatTensor(np.stack([Ix,Iy],axis=0))\n",
    "                    td += -(TD)\n",
    "\n",
    "                # AOP预处理\n",
    "                sd = sd/accumTime\n",
    "                td = td.unsqueeze(0)\n",
    "                td = F.interpolate(td.unsqueeze(0), size=sd.shape[1:], mode='bilinear').squeeze(0)\n",
    "\n",
    "                # 计算OF\n",
    "                rawflow = HS_optical_flow(sd,td,ifInterploted = True,epsilon = 1e-8,maxIteration = 20,labmda=lambda_of_HS,scales = 4)\n",
    "                u = rawflow[0,:, :].numpy()\n",
    "                v = rawflow[1,:, :].numpy()\n",
    "                u = torch.Tensor(cv2.resize(u,(640,320))).unsqueeze(0)\n",
    "                v = torch.Tensor(cv2.resize(v,(640,320))).unsqueeze(0)\n",
    "\n",
    "                #可视化\n",
    "                flow_show = flow_to_image(rawflow.permute(1,2,0).numpy())\n",
    "                flow_show = torch.Tensor(cv2.resize(flow_show,(640,320)))/255.0\n",
    "                flow_show = (flow_show*255).numpy().astype(np.uint8)\n",
    "\n",
    "                mask = np.mean(flow_show,axis=-1) > 225\n",
    "                flow_show[np.stack([mask]*3,axis=-1)]=0\n",
    "\n",
    "                show_img = interpolate_image(show_img,u,v)\n",
    "\n",
    "                td = tsdiff[0:1,(b)*accumTime:(b+1)*accumTime,...] \n",
    "                td = F.interpolate(td,(320,640),mode='bilinear')[0,0,...]\n",
    "                rgb_td = vizDiff(td.cpu(),thresh=3,bg_color='black')\n",
    "                tdiff_show = rgb_td.numpy() \n",
    "                \n",
    "                sparsity = 4\n",
    "                scale = 5\n",
    "                for w in range(640//sparsity):\n",
    "                    for h in range(320//sparsity):\n",
    "                        x = int(w*sparsity)\n",
    "                        y = int(h*sparsity)\n",
    "                        u_ij = -u[0,y,x]\n",
    "                        v_ij = -v[0,y,x]\n",
    "                        color = flow_show[y,x,:]\n",
    "                        color = tuple([int(e+20) for e in color])\n",
    "                        if (u_ij**2+v_ij**2)>1:\n",
    "                            cv2.arrowedLine(flow_show, (x,y), (int(x+u_ij*scale),int(y+v_ij*scale)), color,2, tipLength=0.15)\n",
    "\n",
    "                tdiff_show_tensor = torch.Tensor(tdiff_show.copy())\n",
    "                flow_show_tensor = torch.Tensor(flow_show)\n",
    "                mask = torch.stack([torch.mean(flow_show_tensor,dim=-1)>0]*3,dim=-1)\n",
    "                tdiff_show_tensor[mask] = flow_show_tensor[mask]/255.0\n",
    "                tdiff_show_merge = tdiff_show_tensor.numpy()\n",
    "\n",
    "                imshow1 = np.concatenate([flow_show/255.0,F0show],axis=1)\n",
    "                imshow2 = np.concatenate([tdiff_show,tdiff_show_merge],axis=1)\n",
    "                imshow = np.concatenate([imshow1,imshow2],axis=0)\n",
    "\n",
    "                img_list.append(imshow)\n",
    "\n",
    "                if b %5 ==0:\n",
    "                    clear_output()\n",
    "                    plt.figure(figsize=(6,3))\n",
    "                    plt.axis('off') \n",
    "                    plt.imshow(imshow)\n",
    "                    plt.show()\n",
    "        else:\n",
    "            clear_output()\n",
    "            if not os.path.exists(output_dir):\n",
    "                 os.mkdir(output_dir)\n",
    "            output_name = os.path.join(output_dir,'OF_HS_viz_'+key+'.mp4')\n",
    "            images_to_video(img_list,output_name,size=(640*2,320*2),Flip=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f8366-b03a-49c3-97a0-7ed3cc912130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
