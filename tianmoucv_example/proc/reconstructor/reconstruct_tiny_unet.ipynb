{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f975fb21-58c2-4682-9565-6965173cc6a6",
   "metadata": {},
   "source": [
    "# 轻量化视频重建\n",
    "\n",
    "## 这个示例展示如何使用一个端到端网络融合两个数据通路重建原始场景\n",
    "\n",
    "调用接口：\n",
    "- from tianmoucv.proc.reconstruct.TianmoucRecon_tiny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7018a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205a09e",
   "metadata": {},
   "source": [
    "## 引入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbb65d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys,os, math,time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tianmoucv.data import TianmoucDataReader\n",
    "import torch.nn.functional as F\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051ac49-5ab7-46d3-8987-7348c47ec4eb",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train='/data/lyh/tianmoucData/tianmoucReconDataset/train/'\n",
    "dirlist = os.listdir(train)\n",
    "traindata = [train + e for e in dirlist]\n",
    "\n",
    "val='/data/lyh/tianmoucData/tianmoucReconDataset/test/'\n",
    "vallist = os.listdir(val)\n",
    "valdata = [val + e for e in vallist]\n",
    "key_list = []\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in traindata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "print('---------------------------------------------------')\n",
    "for sampleset in valdata:\n",
    "    print('---->',sampleset,'有：',len(os.listdir(sampleset)),'个样本')\n",
    "    for e in os.listdir(sampleset):\n",
    "        print(e,end=\" \")\n",
    "        key_list.append(e)\n",
    "        \n",
    "all_data = valdata + traindata\n",
    "key_list = ['underbridge_hdr_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe5b60-2de4-4067-9bc6-edfc175bfa7c",
   "metadata": {},
   "source": [
    "## TinyUNet重建网络调用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519407bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from tianmoucv.proc.reconstruct import TianmoucRecon_tiny\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "reconstructor = TianmoucRecon_tiny(ckpt_path=None,_optim=False).to(device)#某些版本python和pytorch无法使用_optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aae273",
   "metadata": {},
   "source": [
    "# 视频输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video(frame_list,name,size=(640,320),Flip=True):\n",
    "    fps = 30        \n",
    "    ftmax = 1\n",
    "    ftmin = 0\n",
    "    out = cv2.VideoWriter(name,0x7634706d , fps, size)\n",
    "    for ft in frame_list:\n",
    "        ft = (ft-ftmin)/(ftmax-ftmin)\n",
    "        ft[ft>1]=1\n",
    "        ft[ft<0]=0\n",
    "        ft2 = (ft*255).astype(np.uint8)\n",
    "        out.write(ft2)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8d860",
   "metadata": {},
   "source": [
    "# 融合图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from IPython.display import clear_output\n",
    "from tianmoucv.isp import vizDiff\n",
    "\n",
    "# 预期重建的区域，以中心向外圈扩展（不超过F0大小）                        \n",
    "w = 640\n",
    "h = 320\n",
    "\n",
    "key_list = ['test_driving_night_light1']\n",
    "for key in key_list:\n",
    "    dataset = TianmoucDataReader(all_data,MAXLEN=500,matchkey=key)\n",
    "    dataLoader = torch.utils.data.DataLoader(dataset, batch_size=1,\\\n",
    "                                          num_workers=4, pin_memory=False, drop_last = False)\n",
    "    img_list = []\n",
    "    count = 0\n",
    "    for index,sample in enumerate(dataLoader,0):\n",
    "        #重建前10帧\n",
    "        if index<= 10:\n",
    "            \n",
    "            # 用于可视化 提前裁切\n",
    "            F0 = sample['F0'][0,...].clone()\n",
    "            biasw = (F0.shape[1]-w)//2\n",
    "            biash = (F0.shape[0]-h)//2\n",
    "            tsdiff = sample['tsdiff'][0,...][biash:h+biash,biasw:w+biasw,:]\n",
    "            F0 = F0[biash:h+biash,biasw:w+biasw,:]\n",
    "            \n",
    "            #channel放到第1维用于推理\n",
    "            sample['F0'] =  sample['F0'].permute(0,3,1,2)\n",
    "            sample['F1'] =  sample['F1'].permute(0,3,1,2)\n",
    "            \n",
    "            '''\n",
    "            输入简单处理过的数据包\n",
    "            输出这个数据包重建的所有帧\n",
    "            F0，F1：0~1\n",
    "            tsdiff：-1~1\n",
    "            ifSingleDirection：是否双向重建取平均\n",
    "            w,h: 感兴趣的区域，设置成F0大小则为全图重建\n",
    "            '''\n",
    "            reconstructed_b = reconstructor(sample,\n",
    "                                            w=w,\n",
    "                                            h=h,\n",
    "                                            bs=26,\n",
    "                                            ifSingleDirection=False).float()\n",
    "            \n",
    "            \n",
    "            timelen = tsdiff.shape[1]\n",
    "            \n",
    "            #最后一帧可以扔掉，或者跟下一次的重建的第0帧做个平均，降低一些闪烁感\n",
    "            for t in range(timelen-1):\n",
    "                tsd_rgb = tsdiff[:,t,...].cpu().permute(1,2,0)*255\n",
    "                td = tsd_rgb.cpu()[:,:,0]\n",
    "                sd = tsd_rgb.cpu()[:,:,1]\n",
    "                rgb_sd = vizDiff(sd,thresh=3).permute(2,0,1)\n",
    "                rgb_td = vizDiff(td,thresh=3).permute(2,0,1)\n",
    "                #数据可视化\n",
    "                rgb_cat = torch.cat([rgb_sd,rgb_td],dim=1)\n",
    "                rgb_tsd = F.interpolate(rgb_cat.unsqueeze(0), scale_factor=0.5, mode='bilinear', align_corners=True).squeeze(0).permute(1,2,0)\n",
    "                reconstructed = reconstructed_b[t,...].cpu()\n",
    "                showim = torch.cat([F0,rgb_tsd,reconstructed.permute(1,2,0)],dim=1).numpy()\n",
    "                # 标注文字\n",
    "                cv2.putText(showim,\"e-GT:\"+str(t),(int(w*1.5)+12,36),cv2.FONT_HERSHEY_SIMPLEX,0.75,(0,0,0),2)\n",
    "                cv2.putText(showim,\"SD:\"+str(t),(int(w)+12,24),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,0),2)\n",
    "                cv2.putText(showim,\"TD:\"+str(t),(int(w)+12,160+24),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,0),2)\n",
    "                cv2.putText(showim,\"COP:0\",(12,36),cv2.FONT_HERSHEY_SIMPLEX,0.75,(0,0,0),2)\n",
    "        \n",
    "                if t==12:\n",
    "                    clear_output(wait=True)\n",
    "                    plt.figure(figsize=(8,3))\n",
    "                    plt.subplot(1,1,1)  \n",
    "                    plt.imshow(showim)\n",
    "                    plt.show()\n",
    "                img_list.append(showim[...,[2,1,0]])\n",
    "        else:\n",
    "            break\n",
    "    images_to_video(img_list,'./viz_'+key+'.mp4',size=(640*2+320,320),Flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a6bdb-decb-4b2a-9df6-ce60d85f4a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
